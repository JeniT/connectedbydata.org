---
layout: post
title: "Connected by data: Why this? Why now?"
author: Jeni Tennison
---
Welcome to this new initiative: [Connected by data](https://connectedbydata.org)!

It almost goes without saying that [data and AI are not working for us](/problems/impact.html) at the moment. The past few decades have seen an explosion in the availability of data, driven both by the web and the ability to put sensors in everything. But we are still, as a society, getting to grips with what this means for us, and how to manage its impact so it helps, rather than harms us.

<!--more-->

The intuitive response to the problems that arise from personal data is to give more control to individuals. The theory is that with more information, more education and more control, people will stop giving data to the services that exploit them and put them at risk. In the wake of the [Facebook / Cambridge Analytica scandal](https://en.wikipedia.org/wiki/Facebook%E2%80%93Cambridge_Analytica_data_scandal), [will.i.am said we need to own our data](https://www.economist.com/open-future/2019/01/21/we-need-to-own-our-data-as-a-human-right-and-be-compensated-for-it), the [Financial Times said privacy rights require data ownership](https://www.ft.com/content/a00ecf9e-2d03-11e8-a34a-7e7563b0b0f4) and any number of companies redoubled their efforts to create [personal data stores](https://en.wikipedia.org/wiki/Personal_data_service) and offer [monetisation opportunities](https://pooldata.io/).

This intuitive response is wrong.

It's also dangerous. In many ways it is like the [individualised response to the climate crisis](https://www.resilience.org/stories/2018-01-10/individual-vs-collective-are-you-responsible-for-fixing-climate-change/). We


These are all things that a lot of us are unhappy about. But what really frustrates me is how many organisations and individuals in the West seem to think – despite the evidence – that the way to solve these problems is by giving us, as individuals, greater [transparency and control](https://twitter.com/robinberjon/status/1486008955306446854) or even [ownership over our data](https://royalsociety.org/-/media/policy/projects/data-governance/data-ownership-rights-and-controls-October-2018.pdf).


During my time at the [Open Data Institute](https://theodi.org), the narrative that I struggled with the most was the


The Facebook / Cambridge Analytica scandal in 2018


These are all things that a lot of us are unhappy about. But what really frustrates me is how many organisations and individuals in the West seem to think – despite the evidence – that the way to solve these problems is by giving us, as individuals, greater [transparency and control](https://twitter.com/robinberjon/status/1486008955306446854) or even [ownership over our data](https://royalsociety.org/-/media/policy/projects/data-governance/data-ownership-rights-and-controls-October-2018.pdf). There's a great paper by Jacob Leon Kröger, Otto Hans-Martin Lutz and Stefan Ullrich called [The Myth of Individual Control: Mapping the Limitations of Privacy Self-management](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3881776) which spells out why this is misconceived. I'm just going to quote their abstract (my emphasis):

> Despite years of heavy criticism, privacy self-management (i.e., the principle that people individually manage their privacy via notice and choice) remains the standard of privacy protection throughout the Western world. Building on previous research, this article provides an overview and classification of the manifold obstacles that render privacy self-management largely useless in practice. **People's privacy choices are typically irrational, involuntary and/or circumventable due to human limitations, corporate tricks, legal loopholes and the complexities of modern data processing. Moreover, the self-management approach ignores the consequences that individual privacy choices have on other people and society at large.** Regarding future research, we argue that **the focus should not be on whether privacy self-management can be fixed by making it more user-friendly or efficient – it cannot**. The concept is based on fundamentally wrong assumptions. To meaningfully address the potentials and dangers of personal data processing in the 21st century, **a shift away from relying purely on individual control is inevitable**. We discuss potential ways forward, stressing the need for government intervention to regulate the social impact of personal data processing.

There is plenty of evidence that "informed consent" is unachievable for the vast majority of people in practice. But for me, the crucial point is the more fundamental one that, in modern usage, data is relational. In other words, my decisions about "my" data affect how systems using that data treat you. This is particularly true when we have a lot in common: when we are related; live in the same house or in the same neighbourhood; travel on the same buses or trains; have the same friends or followers; share similar interests and preferences; or are the same age, or race, or gender, or social class.

I've [written before](http://www.jenitennison.com/2020/12/27/individual-collective-community.html) about how Salome Viljoen's paper [A Relational Theory of Data Governance](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3727562) really clarified for me how modern data processing techniques (aka Big Data and AI) have made these relationships more significant. The societal-level harms, and benefits, that we see are a result of our interconnectedness. When we delegate decision making about data down to only those individuals who contribute data, and get them to make their decisions in isolation, on their own privacy preferences pages, we fundamentally undermine the opportunity for those larger, community-level considerations to come into play. And we diffuse our collective power to make changes to the way data is collected and used, to ensure it benefits us more equitably as a society.

I think we need to find and put into practice ways to make decisions about data – not least those that shape the choices we can then make as individuals – collectively. This isn't a new thing: the GDPR already contains provisions for the use of data for [public tasks](https://ico.org.uk/for-organisations/guide-to-data-protection/guide-to-the-general-data-protection-regulation-gdpr/lawful-basis-for-processing/public-task/) which (whether they are aware of it or not) Parliament determines through representative democracy as it creates and modifies our laws. There is also a growing body of research and experience that highlights how more participative and deliberative approaches can be used, such as the Ada Lovelace Institute's report on [Participatory data stewardship](https://www.adalovelaceinstitute.org/report/participatory-data-stewardship/). In the UK, we've seen a number of successful citizen juries, frequently in and around health, such as the [OneLondon Citizen's Summit](https://www.onelondon.online/wp-content/uploads/2020/07/Public-deliberation-in-the-use-of-health-and-care-data.pdf) or the [citizen juries run by the National Institute for Health Research](https://www.arc-gm.nihr.ac.uk/media/Resources/ARC/Digital%20Health/Citizen%20Juries/Broken%20Files/12621_NIHR_Juries_Report_ELECTRONIC.pdf). And work on [data institutions](https://theodi.org/article/what-are-data-institutions-and-why-are-they-important/) such as [data cooperatives](https://www.opendatamanchester.org.uk/tag/data-cooperatives/) naturally builds in this kind of community-level governance.

But I think we're lacking three things:

1. **Compelling narratives.** While there is substantial work in the data governance community on this topic, the public, press and political narrative about data is still largely oriented towards individual privacy controls. "You own your data" is intuitively attractive and superficially empowering, and who can (or would want to) argue against organisations providing "transparency and control"? We need to find compelling ways to make the case that individual choices aren't powerful enough when we are trapped in [choice architectures](https://en.wikipedia.org/wiki/Choice_architecture) determined for us, and that we have collective interests in the way that data is used that might sometimes override our individual rights. [Martin Tisné's piece in the MIT Technology Review](https://www.technologyreview.com/2021/05/25/1025297/collective-data-rights-big-tech-privacy/) illustrates how analogy – here with safe drinking water – is one way to put this across.

2. **Practical techniques.** There is no one-size-fits-all approach for making collective decisions about data. We need a range of methods from equipping local and national governments to make decisions about data through representative democracy; through large-scale deliberative approaches such as citizen juries; to survey-style approaches that are more suited to cash-strapped SMEs. There is lots of experience to draw on, and, I suspect, a few new approaches that need to be tested, to create practical guides for organisations to adopt.

3. **Legal obligations.** The weakness of a lot of participative approaches for data governance is that they lack teeth: an organisation may hold a citizen jury to understand what's important to their community, but they have no compulsion to adopt the results, especially if they go against their other drivers. I believe we need both changes to the law and effective regulatory institutions to encourage organisations to use these methods, and ensure that the results are meaningfully adopted. (My particular bugbear is strengthening the requirement on organisations who claim "[legitimate interest](https://ico.org.uk/for-organisations/guide-to-data-protection/guide-to-the-general-data-protection-regulation-gdpr/legitimate-interests/)" as their legal basis for data processing to demonstrate how they have performed the balancing test at the heart of their assessment.)

So these are the things that I'm intending to work on over the next few years.
I am extremely fortune to have been awarded a [Shuttleworth Foundation](https://shuttleworthfoundation.org/) fellowship to support this work, at least for the next year. As a first step, I'm looking for a part time [Advocacy and Campaign Director](https://docs.google.com/document/d/1ZU3Z_ZSo3wJ31ruAFwbuvVQdKF7U1ormDg2iQg2qEh4/edit#) to join me. This first year will be focused on both getting the narrative right, engaging with the development of the UK's new data protection legislation so that it encourages meaningful collective approaches, and building out the initiative so it can have a larger impact.

If you are interested in any of this, please do get in touch: [jeni@connectedbydata.org](mailto:jeni@connectedbydata.org).
