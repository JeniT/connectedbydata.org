---
layout: post
author: Jeni Tennison
category: weeknotes
---
I’ve had some wonderfully stimulating conversations this week and it’s been a real luxury being able to have time for them.


## Colonial capitalism in structured data

I had lunch on Wednesday with [Anasuya Sengupta](https://whoseknowledge.org/about-us/who/anasuya-sengupta/) from [Whose Knowledge?](https://whoseknowledge.org/), whom I met at the gathering of the Shuttleworth Foundation fellowship last October. Their work centres the knowledge of the Global Majority on the internet.

Our conversation ranged over a number of topics, but the most delightful was when she asked whether I’d be interested in working on the role of communities in deciding how data should be structured. Delightful because the challenge of how we take a constructivist approach to modelling knowledge – one where we recognise our data models, vocabularies and ontologies are _designed_ rather than _discovered_ – was the subject of my PhD, almost 25 years ago.

When I was doing my PhD I wasn't really thinking about social justice, just the differences that arise between any two people and how they see the world. I understand much better now how the way we model data perpetuates the colonial capitalist view of the world, literally "othering" some people, creating artificial distinctions while also failing to recognise important ones.

My head's been full since, breaking down the problems to be able to explain them but also thinking about approaches to tackling them. I even went back and read a bit of my thesis, which reminded me to see the process of creating an ontology or schema as one of building understanding between people as much as it is one of collaboratively creating something.

I'm looking forward to getting stuck into the details of this with Anasuya and her team.


## Collective intelligence and participation

During our fellowship meet this week we did something a bit different and held a "book club". We all read the first chapter of [The Routledge Handbook of Collective Intelligence for Democracy and Governance](https://www.routledge.com/The-Routledge-Handbook-of-Collective-Intelligence-for-Democracy-and-Governance/Boucher-Hallin-Paulson/p/book/9781032105550), [A brief history of collective intelligence, democracy, and governance](https://www.taylorfrancis.com/chapters/oa-edit/10.4324/9781003215929-2/brief-history-collective-intelligence-democracy-governance-lex-paulson). The chapter does what it says on the tin, and is a whistlestop tour of different societies' ways of governing themselves, with a particular focus in the latter parts on the impact of digital technologies and organising at planetary scale.

I think it's fair to say that as a group we were somewhat critical of the framing of the chapter, but that's what made it a good read to discuss. Just a couple of points that have stuck with me…

I'm not sure how much to lean into the "collective intelligence" concept when we're talking about data governance. Collective intelligence (or the wisdom of the crowd) posits that a group, through independent voting, is more able to come to the right answer about something than any individual. I can see this is useful when trying to predict the future or guess the weight of something, but with data governance I'm not sure there ever _is_ a right answer. Data governance questions aren't questions about facts, but questions about morality, ethics, and values and therefore inherently political.

The counterpoint is that collective intelligence approaches might be a way of discovering what Rousseau called "[the general will](https://en.wikipedia.org/wiki/General_will)". Ask people what they think _others_ think, and you might reveal the truth of that. But this is also dangerous. We know that [people assume others have more conservative views than they actually do](https://theconversation.com/politicians-believe-voters-to-be-more-conservative-than-they-really-are-208053) (the link is about a study of politicians but I'm sure I've seen polling that shows it's a more widespread phenomenon). \[Ed 2023-09-04: See for example this study of [what Americans think other Americans think about climate change](https://www.nature.com/articles/s41467-022-32412-y.)\]

Better, perhaps, to use Rawls' "[veil of ignorance](https://en.wikipedia.org/wiki/Original_position)" where people have to imagine they could end up as anyone in a society, and are asked about the rules they would want. Indeed, [DeepMind have done some research on this](https://www.deepmind.com/blog/how-can-we-build-human-values-into-ai) and found that (per Rawls' prediction) behind a veil of ignorance, people favour rules where AI systems help the most disadvantaged. This also reinforces what has come out in the [Living with Data research](https://livingwithdata.org/resources/data-matters-are-human-matters-summary-of-living-with-data-findings/) about how people in deliberations about data can demonstrate data solidarity: more of a concern about what _others_ might experience than worried on their own behalf.

My conclusion is that less deliberative and political approaches to getting answers to data governance questions could be used in some circumstances, but you have to be careful about how you ask the question. There's also a niggle that we won't actually all agree on what the rules around data or AI should be, even from behind the veil of ignorance, and that this implies the answers to those questions could change over time.

A second area of discussion I was interested in was the impact of participating in deliberations on the participants themselves. The chapter talked about benefits in educating citizens about both the issues they deliberate on, and the process of governance itself. Similarly, I often talk about participation in data governance as a way of improving data literacy as well as understanding of data governance systems and therefore trust (assuming those systems are trustworthy, of course).
