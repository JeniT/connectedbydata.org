---
layout: post
author: Emily Macaulay
category: weeknotes
---

### What I’ve been doing

I had a good run of writing up weekly week notes, and now a month has slipped by so I’m making the effort to get these done.

The past few weeks have been a whirlwind of supporting the logistics for our [People’s Panel on AI](https://connectedbydata.org/projects/2023-peoples-panel-on-ai).  There’s so much to reflect on that alone that I will do separately (hopefully next week).

Of course this has meant (the Panel and the UK’s AI Safety Summit taking place this week) that there is a lot of talk (internally and externally) about AI. My work in **CONNECTED** BY **DATA**, and some freelance work I’m doing to promote inclusivity, both have a strong centre around narratives - storytelling.  Who is doing the telling? Why? What are the words used? And how is the story being passed on?  AI is a really clear current narrative in our public media and more generally in popular culture.

![Image of film poster with an image of a human face with a robotic head and text that reads "created to save us" but the word save is crossed out in blood and replaced with "destroy".]({{site.baseurl}}/assets/blog/2023-11-ai-billboard.jpeg)

Waiting at a train station recently I was confronted with this film poster - literally a story about AI being created for apparently good but actually to destroy us.  When this is the predominant backdrop - reinforced by the UK Government’s Summit focussing entirely on existential “frontier” risk of AI (is it / isn’t it going to kill us all) - how can we hope to engage people in conversations about the real life impacts it is having in our world now (you can read about some of those in a [piece of work our Adam is doing with the TUC](https://connectedbydata.org/events/2023-08-02-impact-of-ai-on-welsh-workers)).

On a lighter note…I also saw this in a hotel I stayed in recently.  I couldn’t decide if it was warning me simply so I didn’t trip over it or because it was out to get me! And either way I imagine if I hadn’t come across a robot cleaner before this may have unnerved me somewhat.

![Image of yellow floor sign that reads "caution robotoic cleaners in operation".]({{site.baseurl}}/assets/blog/2023-11-robotic-cleaner.jpeg)

### What I need to take care of

There’s a lot of wrap up actions around the People’s Panel both in terms of finances (including balancing budgets) and reflecting / sharing lessons learned (individually and collectively).

Then AI continues to dominate and focus switches to supporting the delivery of [our next Design Lab](https://connectedbydata.org/events/2023-11-22-deliberative-governance-data-and-ai) - this one a three day residential in Stroud - where attendees will be exploring and co-creating Resources for Effective & Inclusive Public Deliberation on Data & AI Governance.


### What I’ve been inspired or challenged or moved by

It was a few weeks ago now that I first [saw this video](https://www.youtube.com/watch?v=QNv9PRDIhes) but I’m still loving it.  I wouldn't read Apple's sustainability report. I would possibly glance at a news outlets headline surfacing one key fact. But I watched this from start to finish, undistracted, and in addition to applauding their delivery of this message (and hurrah for Octavia Spencer!) - actually feel hopeful that they're having an impact in the fight against our climate crisis.


### What I’ve been reading

I attended our recent [Connected Conversation](https://connectedbydata.org/projects/2023-connected-conversations) on ‘collective data rights’ ([write up available here](https://connectedbydata.org/events/2023-09-27-connected-conversation-collective-data-rights)) which reminded me of these articles I’d read about collective redress: [Martin Tisne writing](https://www.technologyreview.com/2021/05/25/1025297/collective-data-rights-big-tech-privacy/) about when harm is collective, so must rights be; and [IFoW writing about](https://www.ifow.org/news-articles/regulating-algorithmic-management) regulation of algorithmic management.  This concept of collective - and how a group that may not know they are a group, or that they’ve been impact by “invisible” algorithms, can find each other, come together and then “take on” a (probably strong institution / tech company) seems a real power imbalance to me.  From my lay person, public culturist, perspective I’m reminded of the film Erin Brokovich and how hard her fight was - and that was when the evidence was clearly identifiable, in a defined area, and visibly traceable.  If that was data - or AI - caused, I wonder what needs to happen to make that redress easier (which in turn will change future policy and governance).