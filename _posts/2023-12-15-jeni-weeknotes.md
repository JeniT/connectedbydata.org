---
layout: post
author: Jeni Tennison
category: weeknotes
---
Right, time for a few reflections on a busy year.


## Strategically

I’m seeing a lot more calls now for the democratisation of / public voice in the development of data and AI systems – see the [chairs’ summaries of the roundtables at the AI Safety Summit](https://www.gov.uk/government/publications/ai-safety-summit-1-november-roundtable-chairs-summaries/ai-safety-summit-2023-roundtable-chairs-summaries-1-november--2) for example – but still a massive gap between an understanding this should happen, and the concrete practical and policy steps that would be needed to make it a reality. So I think our focus on campaigning to turn these vague intentions into reality is still a useful one to have.

Generative AI has of course dominated the conversation this year, and created a battle for attention between concerns about long term / existential risks of AI vs present day actual impacts. But it’s also created a subtle drag on conversations about the role of the public: when the kind of AI we care about are global generative AI services, public participation needs to happen at a global scale, where the challenges are things like scaling, representation and how to recognise local/regional diversity. But more generally AI gets deployed – and customised – in local settings: in workplaces, schools, local communities. It has different impacts in different sectors. Some global deliberation might be necessary, but I firmly believe we’ll increasingly need to have deliberation happen at this context-specific and context-aware level – even where generative AI is being used, I think it will increasingly be fine-tuned in those contexts. So rather than scaling public deliberations to happen at national and international levels, we need to focus on scaling the skills for running deliberations at sector, setting and local levels.

I used to think that health was a leading sector on public involvement because of its focus on [PPIE](https://www.nature.com/articles/s41591-023-02445-x) in medical research. I now think that “work” is a leading sector, because unions understand power dynamics and the need for negotiation, as we saw with the [Writers Guild of America agreement](https://www.hollywoodreporter.com/business/business-news/wga-deal-studios-plan-pursue-copyrights-ai-generated-scripts-1235602466/). The low-hanging fruit are likely to be sectors where there are similar existing representative bodies who can engage with, bring together and represent their communities.

The paper [The Participatory Turn in AI Design: Theoretical Foundations and the Current State of Practice](https://arxiv.org/abs/2310.00907) helped me to see the differences between public participation as a mechanism for understanding public attitudes, improving data/AI systems, and actually giving people a powerful say in the technologies that are increasingly dominant in our lives. I understand why different organisations and people will focus on the first two, and that it’s useful rhetorically to emphasise that public participation has benefits for developers, but our focus at Connected by Data is not on developing better data or AI systems, but on creating a better (more equitable, just and sustainable) world, by increasing people’s power.


## Tactically

Getting close to the passage of the [Data Protection and Digital Information (DPDI) Bill](https://connectedbydata.org/resources/dpdib-resources) through the Commons has been eye-opening on several fronts. At the democratic level, at least for technical Bills like this one, Bill Committees cannot provide line-by-line scrutiny or an effective check on government overreach. They do not have the time; the committee members are not experts and have a bunch of other responsibilities; and anyway committees are stacked in favour of the ruling party, with members who will vote whichever way the Government tells them to. Same goes for the Report Stage amendment process, which was [particularly egregious with this Bill due to the large number of last minute Government amendments](https://parliamentlive.tv/event/index/d085ef77-40fd-4d4d-824e-fcddf2b4335c?in=13:16:08). It’s pretty shocking that our only hope for actual democratic scrutiny is from unelected Peers (though I am very thankful for them).

So, I have become a lot more sceptical about engagement with parliament as a way of achieving policy-level changes (as well as with representative democracy overall). I’m also still thinking about the [Rootcause analysis](https://rootcause.global/framing-ai/) that highlighted that we should be thinking of mechanisms other than regulation. Legislating is just one box in the set of things that governments can do to influence systems (see the [“Government as a System” toolkit framework](https://openpolicy.blog.gov.uk/2020/03/06/introducing-a-government-as-a-system-toolkit/) from the Policy Lab), and things like role modelling, contracting, and funding are obvious other things to target. Change can also be made by other actors, in particular through bottom-up demand as I’ve already mentioned. With a General Election coming up, it feels like our policy engagement should shift away from Parliament and towards shaping the agenda for the next Government.

We actually got hands on with public participation this year, through the [People’s Panel on AI](https://connectedbydata.org/projects/2023-peoples-panel-on-ai), which we ran during the AI Safety Summit week, and the [Gloucestershire Data Day](https://dataday.org.uk/) earlier in the year. I’m still wary of being too hands on ourselves (see my earlier comments about scaling skills around running participation exercises), but these both highlighted the power of tangible, targeted examples, particularly where we can demonstrate alternative approaches and tie them to wider messages about the utility and practicality of public participation.

When we started getting civil society people working around data/digital rights together around the DPDI Bill last year, I viewed it mostly as a way of using my immense good fortune in landing an unrestricted grant to fill a coordination gap in the sector that was leading to a bunch of replicated effort, rather than as a way of furthering our specific campaigning goals. As that network has grown and cohered, I’ve started to see the importance of joint civil society action, such as the [Open Letter](https://ai-summit-open-letter.info/) we led with the TUC and ORG around the AI Safety Summit, as another form that the powerful voice we advocate for should take.

Still on the civil society network, it’s really interesting trying to find ways to act in unity and solidarity, not just in coordination, while remaining broad and diverse. For example there’s an argument that as a sector we’d be more impactful if we all focused on the same few goals (eg just three amendments to the DPDI Bill), but that would require some of us to not advocate for the things we’re specifically set up to advocate for. I think rather than reducing the range of our asks, we might be better off just trying to be coherent on the details of them, for example by agreeing on a single set of amendments around automated decision making, rather than different organisations advocating for slightly different changes.


## Organisationally

We’ve grown as an organisation this year, with Adam joining us in January, and Emily and Helena in the middle of the year. That’s definitely enabled us to get more done, and to work to our strengths (Emily joining in particular has given me time and space to get into the content of our work rather than spending a lot of time on organisational management). We’re still all part time (each working 3 or 4 days/week) and working almost entirely remotely (though FullFact have been putting up Jonathan and Adam a couple of days a week).

Not unusually in the third sector, it feels like we’re doing a lot for such a small team, with each of us spread across a lot of different strands of work. It’s hard to de-prioritise things that are interesting and impactful, but they add up in terms of workload and mental load, and bring switching and opportunity costs. The unrestricted funding from the Shuttleworth Foundation has been a luxury that won’t be continuing past the end of February (as they’ve closed up shop), so the need to deliver on project funding will be a useful driver for more focus on the things we really need to do. I wonder if we should start celebrating things we intentionally stop and say no to!


## Personally

When I decided to leave ODI, I wanted to be able to work on something that I genuinely care about (collective approaches to data governance), and to be able to tap into and express that passion. I knew it would take me a while to break out of “[insider mode](https://www.civilsociety.co.uk/voices/andrew-purkis-the-inside-track-or-the-outside-track-for-charities-seeking-change.html)” in the way I think and talk about the changes we need. I’ll probably never be entirely comfortable calling people out, but I do feel like I’m learning to be more confident and emphatic in expressing what I think, largely thanks to Jonathan and Adam for giving me both the words and encouragement.

I also wanted to have time for writing. Honestly, I’m still finding that hard, and there are several half-done reports and written pieces that I would really like to have been able to get published this year and haven’t, because other things have taken priority. Hopefully, my new [fellowship with CIGI](https://www.cigionline.org/) will give me an excuse to do more writing in a way that doesn’t feel too self-indulgent or undirected.

Overall, it’s been an enjoyable and fulfilling year. Here’s to the next one!
