---
layout: post
title: "Data Policy Digest"
author: Gavin Freeguard
category: news
---
Hello, and welcome to the third Data Policy Digest from Connected by Data! The Digest aims to bring you all the main developments in data and digital policy, including the Data Protection and Digital Information Bill, the AI White Paper and beyond. (Often way beyond.)
It’s been more than six weeks since the last edition (I’ve been away). Good job it’s been a quiet month or so in data policy…

If there’s something we’ve missed, something you’re up to that you’d like us to include next time or you have any thoughts on how useful the Digest is or could be, please get in touch via [jonathan@connectedbydata.org](mailto:jonathan@connectedbydata.org). We’re on Twitter @ConnectedByData and @DataReform. You can also catch up on [Digest #1](https://connectedbydata.org/news/2023/04/21/data-policy-digest) and [Digest #2](https://connectedbydata.org/news/2023/05/09/data-policy-digest).

<!--more-->

## Data policy developments


### Deeply DPDIB

Committee stage came to an earlier end than expected – on 23 May, rather than the expected 13 June, which may have led to some organisations scrambling to get their written evidence in. You can read everything that was submitted [on the Bill website](https://bills.parliament.uk/bills/3430/publications#collapse-publication-written-evidence).
 
Committee stage had kicked off with a day of oral evidence, which featured [Connected by Data’s Jeni Tennison](https://connectedbydata.org/events/2023-05-10-dpdi-bill-committee-oral-evidence) and several other civil society groups, alongside voices from business. The transcripts are [on the Bill website](https://bills.parliament.uk/bills/3430/stages/17609).
 
We await details of when the next stage will be – that’ll be the [report stage](https://www.parliament.uk/about/how/laws/passage-bill/commons/coms-commons-report-stage/), where MPs get to consider amendments that were examined in committee.

In the meantime…
* The government has published various [documents about the Bill](https://www.gov.uk/government/publications/data-protection-and-digital-information-bill-impact-assessments), including the Keeling Schedules (which show how the Bill will amend existing laws), updated impact assessments and details of the human rights and equality implications. DSIT also wrote to Damian Collins MP about [consultation requirements](https://twitter.com/hawktalk_blog/status/1668995721452744705) applying to new regulations made under DPDIB. (If one can call it ‘consultation’.)

* The ICO [published a response](https://ico.org.uk/about-the-ico/consultations/information-commissioner-s-response-to-the-data-protection-and-digital-information-no-2-bill/) to the Bill, underlining the Commissioner’s support for it. Though writer Robert Bateman [disagreed with the Information Commissioner](https://twitter.com/RobertJBateman/status/1656583057451675648) about whether the Bill safeguarded his independence.

* ORG looked at the effect of the Bill on [migrants’ data rights](https://www.openrightsgroup.org/publications/briefing-how-the-dpdi-bill-harms-migrants-data-rights/).  

* And [MLex reports](https://mlexmarketinsight.com/news/insight/uk-data-reform-worries-prompt-eu-lawmakers-to-call-for-commission-s-opinion) that UK data reform is back on the EU’s radar, too. And while we’re on the EU, Johnny Ryan, of the Irish Council for Civil Liberties, calls GDPR [an enforcement flop](https://www.economist.com/by-invitation/2023/05/24/dont-be-fooled-by-metas-fine-for-data-breaches-says-johnny-ryan) (or more accurately, the subeditor at The Economist does). Politico has [a similar take](https://www-politico-eu.cdn.ampproject.org/c/s/www.politico.eu/article/record-meta-fine-masks-shortcomings-of-europes-privacy-regime/amp/).

* Finally Javier Ruiz produced an excellent report for the Digital Trade Alliance covering DPDIB and much more looking at ]The United Kingdom’s Post-Brexit Push for Deregulation in Global Data Governance](https://dtalliance.org/uk-global-data-governance-report/).

### Bills, bills, bills

The **Online Safety Bill** has [completed its Lords committee stage](https://bills.parliament.uk/bills/3137/stages) – where peers considered various amendments – and will start report stage on 6 July.
 
There have been calls for better researcher access to platform data: a group of UK academics [signed a letter calling for better access](https://www.mctd.ac.uk/leading-academics-write-to-secretary-of-state-calling-for-increased-and-accelerated-social-media-platform-data-access/), with [support for an amendment](https://www.theguardian.com/technology/2023/jun/19/online-safety-bill-changes-urged-to-allow-access-to-social-media-data). (Mozilla has [launched its own initiative](https://foundation.mozilla.org/en/blog/mozilla-launches-open-source-research-investigations-team-to-probe-platform-algorithms-ai-globally/) to try to fill the gap.) Factchecking charity Full Fact and various health organisations called for [health misinformation](https://fullfact.org/blog/2023/may/fact-checkers-and-leading-health-organisations-urge-government-to-take-health-misinformation-seriously-in-online-safety-bill) to be considered as part of the Bill. More than 80 organisations have signed a letter concerned about [encryption](https://www.openrightsgroup.org/press-releases/online-safety-bill-protect-encrypted-messaging/); journalist Heather Brooke recently write about [the OSB’s role in surveillance](https://www.theguardian.com/commentisfree/2023/jun/06/edward-snowden-state-surveillance-uk-online-safety-bill).

One successful amendment is around [bereaved families being able to access their children’s data](https://twitter.com/mollyroseorg/status/1672114056990162945?s=20) from social media firms, while the government will also move an amendment around jail terms for [sharing explicit images without consent](https://www.bbc.co.uk/news/technology-66021643). Ofcom has published updated guidance on [how it intends to regulate](https://www.ofcom.org.uk/online-safety/information-for-industry/roadmap-to-regulation/0623-update), while [Graham Smith has written](https://www.cyberleagle.com/2023/06/shifting-paradigms-in-platform.html) about the ‘shifting paradigms in platform regulation’ around the OSB, and Politico looks at how the OSB is influencing tech regulation elsewhere, [focusing on Baroness Kidron](https://www.politico.com/news/2023/06/14/british-baroness-online-safety-laws-00101854).
 
The **Digital Markets, Competition and Consumers Bill** is now in [Commons committee stage](https://bills.parliament.uk/bills/3453/stages). Chief exec of the Competition and Markets Authority, Sarah Cardell, touched on the Bill [in a keynote conference speech](https://www.gov.uk/government/speeches/competition-and-innovation-a-priority-for-the-cma), rejecting the idea it could ‘undermine innovation ad growth’. Meanwhile, the Regulatory Policy Committee, which scrutinises the evidence underpinning new legislation, was [not impressed with the Bill’s impact assessment](https://www.gov.uk/government/publications/digital-markets-competition-and-consumers-bill-rpc-opinion-red-rated).
 
The government has also ['fired the starting gun'](https://www.gov.uk/government/news/starting-gun-fired-on-preparations-for-new-product-security-regime) on the new regime for products with internet connectivity, brought into being by the [Product Security and Telecommunications Infrastructure Act](https://bills.parliament.uk/bills/3069), which received royal assent in December.
 
More generally, [the Lords have expressed concern](https://twitter.com/LordSpeaker/status/1656673094558425095) at the use of **secondary legislation**, something which has come up in conversation about several of the digital/data bills.

### AI got ‘rithm

There’s been so much AI-related policy news, I should probably have got ChatGPT to help me structure it.
 
Let’s start in the UK. First, many civil society organisations have been working on their submissions to [the consultation on the AI White Paper](https://www.gov.uk/government/publications/ai-regulation-a-pro-innovation-approach), which closed last week. Our response is [on our website](https://connectedbydata.org/resources/ai-white-paper-2023) (we also [tweeted about it](https://twitter.com/ConnectedByData/status/1671524593121501187)); Big Brother Watch have also [published theirs](https://bigbrotherwatch.org.uk/wp-content/uploads/2023/06/Big-Brother-Watch-response-to-Govt-White-Paper-on-AI.pdf), as have [the TUC](https://www.tuc.org.uk/research-analysis/reports/consultation-response-ai-white-paper) and the [West Midlands Police Data Ethics Committee](https://www.westmidlands-pcc.gov.uk/wp-content/uploads/2023/06/AIRegulationResponseWMPDEC.pdf?x59042); and the Ada Lovelace Institute published [three tests](https://www.adalovelaceinstitute.org/blog/regulating-ai-uk-three-tests/) they would be applying in their analysis (Ada also hosted a roundtable, which [Connected by Data’s Adam](https://connectedbydata.org/events/2023-05-22-ada-lovelace-institute-roundtable) went along to). Keep an eye out for other published responses over the coming days and weeks.
 
AI has received prime ministerial attention. There were [roundtables](https://www.theguardian.com/technology/2023/may/25/no-10-acknowledges-existential-risk-ai-first-time-rishi-sunak) organised by [Number 10](https://twitter.com/RishiSunak/status/1661466378271072257?s=20) and [DSIT](https://www.gov.uk/government/news/technology-secretary-holds-roundtable-with-leading-ai-innovators) – with industry, the civil society and public voice being notably absent. Hopefully that will not be the case with the [international AI summit](https://www.gov.uk/government/news/uk-to-host-first-global-summit-on-artificial-intelligence) the UK will [host in the autumn](https://www.politico.eu/article/u-k-to-host-major-ai-summit-of-like-minded-countries/). The Prime Minister’s [keynote speech](https://www.gov.uk/government/speeches/pm-london-tech-week-speech-12-june-2023) ([video](https://www.youtube.com/watch?v=xo1VkPfpH1s)) at [London Tech Week](https://londontechweek.com/) included the detail that Google DeepMind, OpenAI and Anthropic will give early access to their models ‘for research and safety purposes to help build better evaluations and help us better understand the opportunities and risks of these systems’. (The Centre for the Governance of AI looks at what a [foundation model information-sharing regime](https://www.governance.ai/post/proposing-a-foundation-model-information-sharing-regime-for-the-uk) might look like.) There’s also been chatter about whether the UK could host an international body on AI: the [Washington Post makes the case](https://www.washingtonpost.com/business/2023/06/16/let-the-british-government-write-ai-s-rules/92dd563a-0bfe-11ee-8132-a84600f3bb9b_story.html) for why the UK might actually be well-placed to write global rules on AI. The UN Secretary General thinks such a body might be [a good idea](https://www.reuters.com/technology/un-chief-backs-idea-global-ai-watchdog-like-nuclear-agency-2023-06-12/) (while we’re on the UN, the World Health Organisation has called for [safe and ethical AI in health](https://www.who.int/news/item/16-05-2023-who-calls-for-safe-and-ethical-ai-for-health).) The Economist welcomes the PM’s enthusiasm though thinks his plans fall short, [in an article](https://www.economist.com/leaders/2023/06/15/how-britain-can-become-an-ai-superpower) worth visiting for [the photo alone](https://twitter.com/TheEconomist/status/1669352889645686784).
 
The UK government announcements kept coming… [Ian Hogarth](https://twitter.com/soundboy) will chair [the UK’s new AI Foundation Model Taskforce](https://www.gov.uk/government/news/tech-entrepreneur-ian-hogarth-to-lead-uks-ai-foundation-model-taskforce), announced [back in April](https://www.gov.uk/government/news/initial-100-million-for-expert-taskforce-to-help-uk-build-and-adopt-next-generation-of-safe-ai). He’s written about the taskforce [for The Times](https://twitter.com/soundboy/status/1670827377184604165) (and the Taskforce is [hiring multiple roles](https://www.civilservicejobs.service.gov.uk/csr/index.cgi?SID=b3duZXI9NTA3MDAwMCZzZWFyY2hwYWdlPTEmdXNlcnNlYXJjaGNvbnRleHQ9NDA1NzE1NDAmc2VhcmNoc29ydD1zY29yZSZqb2JsaXN0X3ZpZXdfdmFjPTE4NjM5MzImcGFnZWFjdGlvbj12aWV3dmFjYnlqb2JsaXN0Jm93bmVydHlwZT1mYWlyJnBhZ2VjbGFzcz1Kb2JzJnJlcXNpZz0xNjg3ODU0MjEyLWFiZDY1YjQ4NjIxMjAyOTZiNDQxYzQxMWQxY2EwMWE3NTQ2MzkwZmE=)). We’ve been concerned that recent AI initiatives have lacked civil society, community and public voices – so it’s good to see Ian has set up [a form if you’d like to get in touch](https://twitter.com/soundboy/status/1670827755955429379). He also wrote a piece on the need to ‘slow down the race to God-like AI’ [back in April](https://www.ft.com/content/03895dc4-a3b7-481e-95cc-336a524f2ac2).
 
DSIT announced [£54m in university funding](https://www.gov.uk/government/news/54-million-boost-to-develop-secure-and-trustworthy-ai-research) to develop cutting edge AI. Some £31m will go to work on responsible and trustworthy AI at the University of Southampton – [Responsible AI UK](https://www.rai.ac.uk/) are [on Twitter](https://twitter.com/responsibleaiuk) and have been [tweeting about their team(s)](https://twitter.com/responsibleaiuk/status/1671085930973675523). Southampton’s [Dame Wendy Hall sat down with Sky News’ political editor](https://www.youtube.com/watch?v=Mbf9-d_PBlE), Beth Rigby, to talk all things AI.

It wouldn’t be AI policy without a few joint letters. We signed one [convened by our friends at the Public Law Project](https://publiclawproject.org.uk/latest/government-behind-the-curve-on-ai-risks/), expressing concern that the government’s current approach does not properly protect people from the adverse effects of automated decision making. PLP put forward an alternative white paper with a greater focus on transparency, [picked up by the BBC](https://www.bbc.co.uk/news/uk-politics-65842385) among others. There was also a joint letter [from the Fairness, Accountability, and Transparency (FAccT) community](https://facctconference.org/2023/harm-policy.html), calling for ‘sound policy based on the years of research that has focused on this topic’.
 
Politico have also highlighted [‘the 14 people who matter in UK AI policy’](https://www.politico.eu/article/the-14-people-who-matter-in-uk-ai-policy/). (Civil society and academia are again missing.) Civil Service World have a big feature on [the use of ChatGPT in government](https://www.civilserviceworld.com/in-depth/article/could-chatgpt-transform-civil-service-ai-large-language-models) (and got some officials to [play with it](https://www.civilserviceworld.com/in-depth/article/chatgpt-civil-service-job-chatbot-ai-ministerial-pq-job-application-policy)), while Computer Weekly explored the [risks and opportunities for businesses](https://www.computerweekly.com/feature/ChatGPT-is-creating-a-legal-and-compliance-headache-for-business). The ICO is also [reviewing the use of generative AI](https://ico.org.uk/about-the-ico/media-centre/news-and-blogs/2023/06/don-t-be-blind-to-ai-risks-in-rush-to-see-opportunity/).
 
**Elsewhere…** Former prime minister of New Zealand, Jacinda Ardern, wrote for the Washington Post: [‘There’s a model for governing AI. Here it is.’](https://www.washingtonpost.com/opinions/2023/06/09/jacinda-ardern-ai-new-zealand-planning) Spoiler: it’s a collaborative, multi-stakeholder one. IEEE has looked at [the different international approaches](https://spectrum.ieee.org/ai-regulation-worldwide).
 
**In the US**, the White House has also announced [various actions](https://www.whitehouse.gov/briefing-room/statements-releases/2023/05/04/fact-sheet-biden-harris-administration-announces-new-actions-to-promote-responsible-ai-innovation-that-protects-americans-rights-and-safety/), with President Biden meeting [several CEOs](https://twitter.com/POTUS/status/1654237472065302528). There have been [Senate](https://www.judiciary.senate.gov/committee-activity/hearings/oversight-of-ai-rules-for-artificial-intelligence) Committee [hearings](https://www.bbc.co.uk/news/live/world-us-canada-65610337), and the House Committee on Science, Space and Technology has also heard from witnesses on [‘Artificial Intelligence: Advancing Innovation Towards the National Interest’](https://science.house.gov/2023/6/artificial-intelligence-advancing-innovation-towards-the-national-interest). It’s not just in the UK where there’s a sense of falling behind, as Fast Company looks at [Senate Majority Leader Chuck Schumer’s efforts](https://www.fastcompany.com/90895351/chuck-schumers-effort-to-get-ahead-of-ai-may-already-be-falling-behind). The Washington Post, meanwhile, went [‘Inside the Senate’s crash course on “AI 101”’](https://www.washingtonpost.com/politics/2023/06/14/inside-senates-crash-course-ai-101/). New York Magazine has an [interview with FTC chair, Lina Khan](https://nymag.com/intelligencer/2023/05/on-with-kara-swisher-ftc-chair-lina-khan-on-ai-and-musk.html) on how to regulate big tech and AI. (Incidentally, the FTC has started clamping down on [dark patterns when it comes to unsubscribing from services](https://twitter.com/linakhanFTC/status/1671530338852405250) – starting with Amazon Prime.)
 
**In Europe**, Access Now was pleased with ‘a much-improved’ EU AI Act, though [still has concerns](https://www.accessnow.org/press-release/historic-vote-in-the-european-parliament-dangerous-ai-surveillance-banned-but-not-for-migrant-people-at-the-borders/) – [as does EDRI](https://edri.org/our-work/eu-parliament-plenary-ban-of-public-facial-recognition-human-rights-gaps-ai-act/). Computer Weekly [has a report](https://www.computerweekly.com/news/366537455/MEPs-vote-in-raft-of-amendments-to-EU-AI-Act). Law firm Burges Salmon have [published a flowchart](https://twitter.com/sebkrier/status/1669346257368907777) to help people understand the AI Act.  Marietje Schaake, adviser to European Commissioner for Competition, Margrethe Vestager, wrote that [‘We need to keep CEOs away from AI regulation’](https://www.ft.com/content/5f8b74f7-68b1-4a6c-88bf-d0dd03579149). Politico goes inside [an apparent fight](https://www.politico.eu/article/czar-wars-margrethe-vestager-thierry-breton-fight-over-ai-throne/) between Vestager and internal market commissioner, Thierry Breton, over AI. [Stanford University research](https://crfm.stanford.edu/2023/06/15/eu-ai-act.html) has looked at how foundation models would comply with the Act. And we shouldn’t forget [the Council of Europe’s](https://www.politico.eu/newsletter/digital-bridge/one-treaty-to-rule-ai-global-politico-transatlantic-data-deal/) treaty efforts ([more here](https://dpoblog.eu/negotiations-in-the-council-of-europe-on-the-convention-on-artificial-intelligence-the-ongoing-story-of-the-mountain-which-labored-and-brought-forth-a-mouse) from an unimpressed anonymous data protection officer).
 
Some of the **big AI companies** made news beyond their various high level political meetings. OpenAI’s CEO says the age of large models is already over, [according to Wired](https://www.wired.com/story/openai-ceo-sam-altman-the-age-of-giant-ai-models-is-already-over/); while OpenAI dealt with [a leaked document](https://time.com/6288245/openai-eu-lobbying-ai-act/) suggesting they were lobbying to water down regulation (contrary to their public position); and AI expert Hal Daumé III looked [through another OpenAI governance document](https://twitter.com/haldaume3/status/1661088984834113536) (spoiler: he was unimpressed). DeepMind is proposing [a new framework](https://www.deepmind.com/blog/an-early-warning-system-for-novel-ai-risks) for thinking about novel risks.
 
And the trilogy of **AI godfathers** (the three winners of the 2018 Turing Award) continue to provide as much drama as any Francis Ford Coppola film. One, Meta’s Yann LeCun, [does not think AI will take over the world or destroy jobs](https://www.bbc.co.uk/news/technology-65886125). Another, Yoshua Bengio, [‘feels 'lost' over life's work’](https://www.bbc.co.uk/news/technology-65760449). The third, Geoffrey Hinton, who quit Google a few weeks ago, gave a lecture at Cambridge on [‘Two Paths to Intelligence’](https://www.cser.ac.uk/news/geoff-hinton-public-lecture/) – the New Statesman also interviewed him in a piece called [‘The godfathers of AI are at war’](https://www.newstatesman.com/long-reads/2023/06/men-made-future-godfathers-ai-geoffrey-hinton-yann-lecun-yoshua-bengio-artificial-intelligence). Though useful for understanding Hinton’s view, that didn’t really get at why his resignation proved so controversial – former Googlers [expressing their disappointment](https://www.fastcompany.com/90891995/i-didnt-see-him-show-up-ex-googlers-blast-ai-godfather-geoffrey-hintons-silence-on-fired-ai-experts) to Fast Company about his silence when they quit while ringing alarm bells over AI. In general, there is much media coverage and [alarmism](https://twitter.com/Jackstilgoe/status/1665258185031143424?s=20) over existential risks – government adviser Matthew Clifford felt the need to call for calm over how [some of his comments had been represented](https://twitter.com/matthewclifford/status/1665967012676345859) – at the expense of thinking about the harms AI can already cause. Signal president [Meredith Whittaker](https://www.fastcompany.com/90892235/researcher-meredith-whittaker-says-ais-biggest-risk-isnt-consciousness-its-the-corporations-that-control-them), former UK cybersecurity chief [Ciaran Martin](https://twitter.com/ciaranmartinoxf/status/1655482414213341188?s=20), and technologist [Rachel Coldicutt](https://rachelcoldicutt.medium.com/on-understanding-power-and-technology-1345dc57a1a) are among many calling for a more measured and realistic focus on AI harms.

### DSIT up and take notice

Beyond all the AI activity… DSIT published the long-awaited [National Semiconductor Strategy](https://www.gov.uk/government/news/new-1-billion-strategy-for-uks-semiconductor-sector). Mentions of ‘world leading’: 8; mentions of ‘world-leading’: 9. We’re world-leading in the number of government strategies around data, digital and tech, if nothing else. DSIT has also published some [research on the UK’s safety tech sector](https://www.gov.uk/government/news/uk-leads-the-world-in-providing-tech-to-keep-us-safe-online).
 
The Centre for Data Ethics and Innovation published [‘Enabling responsible access to demographic data to make AI systems fairer’](https://www.gov.uk/government/publications/enabling-responsible-access-to-demographic-data-to-make-ai-systems-fairer). Data policy veterans may recall this was a subject covered by the government’s [Data: a new direction](https://www.gov.uk/government/consultations/data-a-new-direction) consultation back in autumn 2021, though it didn’t feature in DPDIB or the AI White Paper. CDEI also published [a portfolio of tools](https://www.gov.uk/guidance/cdei-portfolio-of-ai-assurance-techniques) for assuring AI systems.
 
The Geospatial Commission published the [Geospatial Strategy 2030](https://www.gov.uk/government/publications/uk-geospatial-strategy-2030), which has lots on data and harnessing AI. You can also [read all the submissions](https://www.gov.uk/government/consultations/call-for-evidence-geospatial-opportunities-across-the-economy) to one of the consultations informing the strategy.
 
The ministers have been busy. Secretary of State, Chloe Smith, spoke at [London Tech Week](https://www.gov.uk/government/speeches/secretary-of-state-speech-to-london-tech-week), the [Global Forum for Technology](https://www.gov.uk/government/speeches/secretary-of-state-opening-speech-at-global-forum-for-technology), and the [Robotics and Automation Conference](https://www.gov.uk/government/speeches/secretary-of-states-opening-speech-at-robotics-and-automation-conference). AI minister, Viscount Camrose, is [now on Twitter](https://twitter.com/JonathanCamrose) (he’s not currently following any of the civil society organisations interested in data and AI – maybe we should make him a list?). DSIT minister Paul Scully failed to [make the shortlist](https://conservativehome.com/2023/06/12/shortlist-of-three-chosen-for-conservative-candidate-to-be-mayor-of-london/) to be Tory candidate for London mayor ([PUBLIC](https://www.public.io/) technology entrepreneur and former Cameron adviser, Daniel Korski, did – although has been [hit by controversy](https://www.bbc.co.uk/news/uk-england-london-66026515)). And science minister, George Freeman, is the latest guest on the [BBC’s Political Thinking podcast](https://www.bbc.co.uk/sounds/play/m001n8fp).
 
DSIT has also been busy internationally, holding [a dialogue with Singapore, agreeing cooperation with Canada](https://www.gov.uk/government/news/the-uk-singapore-cyber-dialogue) on quantum technologies, reaching [an in principle agreement with the US](https://www.gov.uk/government/news/uk-and-us-reach-commitment-in-principle-over-data-bridge) on a ‘data bridge’, and agreeing [strengthened science and tech ties](https://www.gov.uk/government/news/uk-and-japan-strengthen-science-and-tech-ties-in-tokyo) and a semiconductors [partnership with Japan](https://www.gov.uk/government/publications/uk-japan-semiconductors-partnership-joint-statement).

### Labour movement

Tech Monitor have just published a long piece asking [‘what are Labour’s tech policies, exactly?’](https://techmonitor.ai/policy/digital-economy/so-what-are-labours-tech-policies-exactly) It features our own Jeni, who gets the last word: she’s looking for Labour ‘to really face the fact that data and AI is political. It’s about power – and it’s about whose side you are on as a government’.
 
This came after Labour leader, Keir Starmer, [told London Tech Week](https://www.youtube.com/watch?v=lF6OpisTA68) that the UK should avoid the same [mistakes as deindustrialisation](https://news.sky.com/story/keir-starmer-warns-ai-could-worsen-inequality-and-leave-some-communities-poorer-12901362) with AI technology advances, and that – while there is a risk of communities being left poorer – there are also opportunities for the public good. [He wrote for The Independent](https://www.independent.co.uk/independentpremium/voices/labour-ai-jobs-workers-b2356127.html) along the same lines. Ahead of techUK’s Policy Leadership Conference, shadow digital secretary [Lucy Powell spoke to the Guardian](https://www.theguardian.com/technology/2023/jun/05/ai-could-outwit-humans-in-two-years-says-uk-government-adviser) about Labour’s emerging tech policy, including licensing and tighter rules for those developing AI. And shadow chancellor, Rachel Reeves, channelled Harold Wilson, touching on the ‘green heat of technology’ in [a New Statesman profile](https://www.newstatesman.com/long-reads/2023/06/reeves-doctrine-labours-plan-power-shadow-chancellor-washington-dc-jason-cowley).
 
More generally, the Party is giving more detail on its [five missions](https://labour.org.uk/missions/), most recently in a speech about making Britain [a clean energy superpower](https://labour.org.uk/press/keir-starmer-speech-unveiling-labours-mission-to-cut-bills-create-jobs-and-provide-energy-security-for-britain/). And there was [a leak of the various policy proposals](https://labourlist.org/2023/05/labour-manifesto-2024-election-what-policies-npf-party/) collated by the National Policy Forum (submitted by party members and affiliates as part of Labour’s internal policy processes), which could give a clue to some of the ideas that might make it into a manifesto.

### Parly-vous data?

Labour MP, Mick Whitley, introduced a private members’ bill to the Commons: the [Artificial Intelligence (Regulation and Workers' Rights) Bill](https://hansard.parliament.uk/commons/2023-05-17/debates/09100FA7-691B-45F7-AFAE-4952472BD100/ArtificialIntelligence(RegulationAndWorkers%E2%80%99Rights)). It follows his [Westminster Hall debate on AI and the Labour Market](https://hansard.parliament.uk/Commons/2023-04-26/debates/0E66B478-1A0B-4F49-9517-F2A91D6365F3/details) back in April. (More on Mick below.)
 
And in Cardiff Bay… a member of the Senedd used ChatGPT to [write a speech on Wales winning the World Cup of Darts](https://www.bbc.co.uk/news/uk-wales-politics-65976541). You can decide for yourself whether it hit the bullseye, or was just a load of bull, [using TheyWorkForYou](https://www.theyworkforyou.com/senedd/?id=2023-06-21.6.513908.h&s=darts+section%3Awales#g6.513909) which now covers the Welsh Parliament.

### In brief

Making a mockery of that subheading, there’s been quite a lot:
* The Lords Communications and Digital Committee will launch an inquiry into LLMs before summer recess, [reported Politico](https://twitter.com/F1/status/1671918472048312320). There’s already a Lords select committee looking into [AI in weapon systems](https://committees.parliament.uk/committee/646/ai-in-weapon-systems-committee/), which takes more oral evidence on 29 June.

* The Department of Health and Social Care has announced a [£21m fund to help roll out](https://www.gov.uk/government/news/21-million-to-roll-out-artificial-intelligence-across-the-nhs) AI across the NHS. Also in health data news, Palantir have been [awarded £25m](https://www.digitalhealth.net/2023/06/nhs-england-awards-25-million-contract-to-palantir-to-transition-to-fdp/) to transition its data to the NHS’s new Federated Data Platform – that contract will be awarded in the coming months – just as Foxglove and the Doctors’ Association UK sent [a report](https://www.politico.eu/wp-content/uploads/2023/06/16/Foxglove-Palantir-report.pdf) to [MPs warning](https://techmonitor.ai/government-computing/palantir-federated-data-platform-fdp-nhs-england) of seven key risks. The government has also commissioned [a review of the health data landscape](https://www.hdruk.ac.uk/news/uk-health-data-landscape-review-commissioned/)

* The Department for Education are [consulting on the use of generative AI in education](https://www.gov.uk/government/consultations/generative-artificial-intelligence-in-education-call-for-evidence) – you’ve got until 23 August to submit your thoughts. Schools Week [have a write-up](https://schoolsweek.co.uk/minister-wants-schools-to-benefit-from-ai-revolution/) – while Public First have done [some polling about the use of AI for different tasks](https://jonathansimons1982.medium.com/sunday-thoughts-when-it-comes-to-ai-in-education-are-the-facts-of-life-traditional-4e63f97e873a). Meanwhile, the FT explored [what AI is already doing in education](https://www.ft.com/content/47fd20c6-240d-4ffa-a0de-70717712ed1c), and the [second global ‘Day of AI’ took place](https://www.edweek.org/technology/day-of-ai-spurs-classroom-discussions-on-societal-impacts-of-artificial-intelligence/2023/05)

* DCMS has published the [‘Creative industries sector vision’](https://www.gov.uk/government/publications/creative-industries-sector-vision/creative-industries-sector-vision-a-joint-plan-to-drive-growth-build-talent-and-develop-skills), which mentions ‘a code of practice for text and data mining’

* The ICO ‘warns of [“real danger” of discrimination in new technologies that monitor the brain’](https://ico.org.uk/about-the-ico/media-centre/news-and-blogs/2023/06/ico-warns-of-real-danger-of-discrimination-in-new-technologies-that-monitor-the-brain/). The regulator is also looking at the [use of personal data in the government’s anti-disinformation work](https://www.civilserviceworld.com/professions/article/ico-use-personal-data-government-counter-disinformation-unit) – just as Big Brother Watch reported that Green MP [Caroline Lucas had been logged](https://bigbrotherwatch.org.uk/2023/06/caroline-lucas-mp-logged-by-secretive-government-disinformation-unit/).

* The UK Open Government Network called for ideas for UK’s next Open Government National Action Plan. [Keep an eye on their website](https://opengovernment.org.uk/) for details of how to get involved in the next stage of the process, where civil society and the government will co-create a plan

* And while we’re on open government… the Ministry of Justice are [consulting on open justice](https://www.gov.uk/government/consultations/open-justice-the-way-forward) – you have until 7 September to submit your views

* The Cabinet Office has (finally) announced [details of its review of the UK Statistics Authority](https://www.gov.uk/government/publications/independent-review-of-the-uk-statistics-authority-uksa-2023/independent-review-of-the-uksa-announcement-html) – you have until 7 July if you have views

* [The list of EU law](https://www.gov.uk/government/publications/schedule-of-retained-eu-law) that will be revoked or sunsetted at the end of this year includes a few regulations around data and information

* There’s [a focus on AI and automation](https://www.gov.uk/government/publications/the-no10-innovation-fellowship-programme) in the latest round of No 10 Innovation fellowships

* UK police’s use of facial recognition [could be expanded](https://techmonitor.ai/technology/ai-and-automation/uk-police-facial-recognition-technology-chris-philp-cctv). Biometrics and surveillance camera commissioner, Fraser Sampson, was [less than impressed](https://www.theguardian.com/uk-news/2023/may/16/ministers-calling-for-facial-recognition-technology-in-police-bodycams).

* [Around 90 organisations](https://www.theguardian.com/business/2023/may/30/capita-cyber-attack-data-breaches-ico), including many in the public sector, have been affected by a cyberattack on outsourcing group, Capita.

* Politico has a bit of [a debrief on London Tech Week](https://www.politico.eu/newsletter/politico-london-influence/london-influence-tech-week-debrief-starmers-big-weekend-devolution-revolution-2/), as does tech journalist Chris Stokel Walker [in the Evening Standard](https://www.standard.co.uk/insider/london-tech-week-2023-moments-vr-event-b1088143.html)

* And of course there’s [a data protection angle](https://twitter.com/MissIG_Geek/status/1669289280391323649) to former digital secretary Nadine Dorries’ [Schrödinger’s resignation](https://www.theguardian.com/politics/2023/jun/14/nadine-dorries-failure-to-resign-officially-as-mp-frustrates-sunaks-attempt-to-reset-tories) from parliament. She’s still technically an MP.

## What we’ve been up to

It’s been…. somewhat busy:
* On 20 June, we organised [an event with the TUC in parliament](https://connectedbydata.org/events/2023-06-20-worker-experience-of-the-ai-revolution) on ‘the worker experience of the AI revolution’. Chaired by our very own Jeni and the TUC’s Mary Towers, we heard from three workers already dealing with the consequences of tech at work: Garfield Hylton, who works at Amazon, and whose data story is one of those [featured in our recent report](https://connectedbydata.org/resources/our-data-stories); [Luke Elgar](https://twitter.com/luke_elgar), from the Royal Mail; and [Laurence Bouvard](https://twitter.com/Lauloknows), actress and voiceover artist. We had three politicians on the panel: Labour’s Mick Whitley, who is sponsoring [a private members’ bill on Artificial Intelligence (Regulation and Workers' Rights)](https://bills.parliament.uk/bills/3464), shadow data minister Steph Peacock and former tech minister Damian Collins. There were a lot of parliamentarians in the audience to hear from the workers, too. You can catch up via [our live-tweeting from the event](https://twitter.com/ConnectedByData/status/1671194476453277706).

* We’ve been at various conferences: Jeni and Tim were in Costa Rica for RightsCon, where we co-hosted [a policy design lab](https://connectedbydata.org/events/2023-06-04-policy-design-lab) and roundtable on ‘a global policy agenda on collective data governance’ with with Aapti Institute, Research ICT Africa, Aapti Institute and The Datasphere Initiative, and Jeni spoke on a panel about [reimagining data rights](https://twitter.com/JeniT/status/1663808491557904384); and I headed to the [MyData conference](https://2023.mydata.org/) in lovely [Helsinki](https://twitter.com/GavinFreeguard/status/1663557221882667010) to talk about collective data futures, alongside others including [Demos Helsinki](https://demoshelsinki.fi/julkaisut/to-change-system-settings-click-here/).

* We convened a [‘Future Data Narratives Design Lab’](https://connectedbydata.org/events/2023-05-25-narrative-design-lab), aiming ‘to start the co-creation of a strategy for shifting the inaccurate, damaging way data is currently framed & understood in media, policy and industry narratives’.

* Tim blogged about [data values](https://connectedbydata.org/blog/2023/06/03/what-can-barometer-tell-data-values) – [twice](https://connectedbydata.org/blog/2023/06/04/what-secondary-data-might-barometer-use-data-values) – and [LLMs](https://connectedbydata.org/blog/2023/06/02/large-language-models-expert-survey), building on the Global Data Barometer.

* We’re also thinking about our plans for party conference season in September/October. If you’re going, and looking for speakers, do get in touch.

## What everyone else has been up to

* The Ada Lovelace Institute are [advertising for some researchers](https://www.adalovelaceinstitute.org/job/researchers-june-2023/) to work on the impacts of data and AI on society. Apply before 19 July

* Ada have also published a couple of reports in recent weeks: on [how people feel about AI](https://www.adalovelaceinstitute.org/report/public-attitudes-ai/) with the Alan Turing Institute, and on insights and lessons from the use of [technology during the Covid-19 pandemic](https://www.adalovelaceinstitute.org/report/covid-19-lessons-app-store/)

* ORG published a report on the [Information Commissioner’s Office during the pandemic](https://www.openrightsgroup.org/press-releases/org-report-finds-that-ico-failed-to-hold-the-government-to-account-over-use-of-public-health-data-during-pandemic/). The ICO has also been criticised by lawyers and data protection experts, [according to Computer Weekly](https://www.computerweekly.com/news/366542617/ICO-under-fire-for-taking-limited-action-over-serious-data-breaches)

* techUK launched a [UK Tech Plan](https://www.techuk.org/resource/a-uk-tech-plan-how-the-next-government-can-use-technology-to-build-a-better-britain.html) at their Policy leadership Conference

* The Digital Trade Alliance have published a report on [‘The United Kingdom’s Post-Brexit Push for Deregulation in Global Data Governance’](https://dtalliance.org/uk-global-data-governance-report/)

* Demos published [‘Rewiring The Web: The future of personal data’](https://demos.co.uk/research/rewiring-the-web-the-future-of-personal-data/)

* The Tony Blair Institute for Global Change also published [a paper on digital identity](https://www.institute.global/insights/tech-and-digitalisation/great-enabler-transforming-future-of-britains-public-services-digital-identity), and published [‘A New National Purpose: AI Promises a World-Leading Future of Britain’](https://www.institute.global/insights/politics-and-governance/new-national-purpose-ai-promises-world-leading-future-of-britain) which… does not pull its punches

* BCS published a report on [‘Helping AI grow up without pressing pause’](https://www.bcs.org/articles-opinion-and-research/helping-ai-grow-up-without-pressing-pause/)

* Big Brother Watch published a report on [‘Biometric Britain’](https://twitter.com/BigBrotherWatch/status/1660963331727933441?s=20)

* Prospect conducted some polling which found [‘Almost 60% of people want regulation of AI in UK workplaces’](https://www.theguardian.com/technology/2023/may/31/almost-60-of-people-call-for-regulation-of-ai-in-uk-workplaces-research-reveals)

* Natalie Byrom [responded](https://twitter.com/NatalieByrom/status/1671855214196826118) to reports that the Lord Chief Justice [wants victims of crime to use AI](https://committees.parliament.uk/oralevidence/13302/pdf/#page=26) to understand their chances of success in court

* Jess Morley published [a guide to thinking critically about AI in healthcare](https://twitter.com/jessRmorley/status/1663513700806868993)

* Policy Connect and the APPG on data analytics published a report, [‘An Ethical AI Future: Guardrails & Catalysts to make Artificial Intelligence a Force for Good’](https://www.policyconnect.org.uk/research/ethical-ai-future-guardrails-catalysts-make-artificial-intelligence-force-good).

* Chatham House has launched [a taskforce on Responsible AI and Society](https://www.chathamhouse.org/about-us/our-departments/digital-society-initiative-dsi/responsible-ai-and-society)

* Rachel Coldicutt has set up an [‘Everyday Automation Observatory’](https://padlet.com/rachel1374/everyday-automation-observatory-4qefr07x028bnbqq)

* Taiwanese digital minister Audrey Tang is exploring [‘alignment assemblies’](https://twitter.com/audreyt/status/1661932850294448129?s=20) to involve the public in shaping AI. Audrey also co-authored an article on [how random selection could help with that](https://fortune.com/2023/06/20/why-picking-citizens-at-random-best-way-to-govern-ai-revolution-tech-politics/).

* UCL’s Institute for Innovation and Public Purpose published a briefing on [the importance of digital disclosures in helping to regulate big tech](https://www.ucl.ac.uk/bartlett/public-purpose/publications/2023/jun/regulating-big-tech-through-digital-disclosures)

* And the Institute for Government has hosted two Data Bites events since our last Digest – a second [justice data special](https://www.instituteforgovernment.org.uk/event/data-bites-42-getting-things-done-data-government) and [a smorgasbord](https://www.instituteforgovernment.org.uk/event/data-bites-43-getting-things-done-data-government) of different government data projects. The 44th edition is on [Monday 10 July](https://www.instituteforgovernment.org.uk/event/data-bites-44-getting-things-done-data-government).


## Events

* On Tuesday 27 June, the Open Rights Group, Big Brother Watch, TUC, Keep Our NHS Public and Bates Wells were talking DPDIB in parliament [at an event](https://www.eventbrite.co.uk/e/what-will-it-mean-to-weaken-the-uks-data-protection-regime-tickets-651939758367?aff=ebdsoporgprofile) organised by SOAS’s Influencing the Corridors of Power project. (SOAS ICOP have produced their own briefing on the Bill.)

* Also today, the Global Government Forum has a discussion, [‘AI for all? Addressing the biases in automation’](https://twitter.com/globegov/status/1671488428637143041?s=20)

* [London Data Week](https://www.londondataweek.org/) is happening from 3 to 9 July. The ODI are among those holding events ([on art and data](https://www.eventbrite.co.uk/e/canalside-chat-in-the-pink-how-art-and-data-are-driving-london-forwards-tickets-652135052497)), while Science Gallery London gets in just before the start with [‘Building better AI in the open’](https://www.eventbrite.co.uk/e/building-better-ai-in-the-open-tickets-648765644507)

* On Tuesday 18 July, Defend Digital Me are in parliament hosting an event on [‘AI and Education: existential threat or an everyday toolkit?’](https://defenddigitalme.org/event-ai-and-education-existential-threat-or-an-everyday-toolkit/)

* And… [Open Data Camp returns](https://www.odcamp.uk/open-data-camp-8-wolverhampton-1-2-july-2023/) this weekend (1-2 July), in Wolverhampton.


## Good reads

Plenty on AI, as you might expect:
* In the New York Times, Daron Acemoglu and Simon Johnson (who have [a new book out](https://ilp.mit.edu/node/59183) on power, tech and prosperity) worry that [big AI will be worse than big tech](https://www.nytimes.com/2023/06/09/opinion/ai-big-tech-microsoft-google-duopoly.html).

* AI expert Reuben Binns was quoted in an article about AI and actors. [Except…](https://twitter.com/RDBinns/status/1670316342195507200)

* From Tech Policy Press: [‘Will Open Source AI Shift Power from ‘Big Tech’? It Depends.’](https://techpolicy.press/will-open-source-ai-shift-power-from-big-tech-it-depends/)

* From The Hill: [‘Artificial intelligence doesn’t have to be inhumane’](https://thehill.com/opinion/technology/4047323-artificial-intelligence-doesnt-have-to-be-inhumane/)

* From The Economist: [‘The bigger-is-better approach to AI is running out of road’](https://www.economist.com/science-and-technology/2023/06/21/the-bigger-is-better-approach-to-ai-is-running-out-of-road)

* IEEE asked several AI experts about their worries to come up with [‘The AI Apocalypse: A Scorecard’](https://spectrum.ieee.org/artificial-general-intelligence)

* From The Verge: [‘AI Is a Lot of Work’](https://www.theverge.com/features/23764584/ai-artificial-intelligence-data-notation-labor-scale-surge-remotasks-openai-chatbots)

* From the New Republic: [‘The Great A.I. Hallucination’](https://newrepublic.com/article/172454/great-ai-hallucination-chatgpt)

* From Motherboard: [‘AI Is Tearing Wikipedia Apart’](https://www.vice.com/en/article/v7bdba/ai-is-tearing-wikipedia-apart)

* From Data & Society: [‘Algorithms’ Transparency Problem is Everyone’s Problem’](https://points.datasociety.net/algorithms-transparency-problem-is-everyone-s-problem-9a28e7e88cdb)

* From The Guardian: [‘AI machines aren’t ‘hallucinating’. But their makers are’](https://www.theguardian.com/commentisfree/2023/may/08/ai-machines-hallucinating-naomi-klein)

* From the Sociological Review: [‘Predicted benefits, proven harms: How AI’s algorithmic violence emerged from our own social matrix’](https://thesociologicalreview.org/magazine/june-2023/artificial-intelligence/predicted-benefits-proven-harms/)

* From Cambridge’s Ross Anderson: [‘Will GPT models choke on their own exhaust?’](https://www.lightbluetouchpaper.org/2023/06/06/will-gpt-models-choke-on-their-own-exhaust/)

* Ethan Zuckerman in Prospect: [‘When AI thinks you’re dead’](https://www.prospectmagazine.co.uk/ideas/technology/61270/when-ai-thinks-youre-dead-chat-gpt-hallucination)

* A 2022 paper from AI and Society, [‘Against “Democratising AI’](https://link.springer.com/article/10.1007/s00146-021-01357-z), is doing the rounds – Jeni [blogged her thoughts](https://connectedbydata.org/weeknotes/2022/07/29/jeni-weeknotes) on it last year.
 
A few pieces on how data and AI has, or could, affect us and our governments:
* Guardian Australia journalists look back at [how they covered the ‘robodebt’ scandal, around automated decision making](https://www.theguardian.com/media/2023/may/04/how-two-reporters-exposed-centrelinks-robodebt-injustice-and-gave-voice-to-the-victimised).

* From The Guardian: [‘Automated UK welfare system needs more human contact, ministers warned’](https://www.theguardian.com/society/2023/may/22/automated-uk-welfare-system-needs-more-human-contact-ministers-warned)

* From The Markup: [‘From “Heavy Purchasers” of Pregnancy Tests to the Depression-Prone: We Found 650,000 Ways Advertisers Label You’](https://themarkup.org/privacy/2023/06/08/from-heavy-purchasers-of-pregnancy-tests-to-the-depression-prone-we-found-650000-ways-advertisers-label-you)

* From the New York Times: [‘The World’s Digital Memory Is at Risk’](https://www.nytimes.com/2023/06/21/opinion/digital-archives-memory.html)

* [Better Government Tech is Possible](https://www.wired.com/story/government-technology-artificial-intelligence/), writes Beth Simone Noveck for Wired

* CIGI look at Canada and [why a lag in reporting data breaches matters](https://www.cigionline.org/articles/a-report-card-on-the-canadian-federal-governments-response-to-data-breaches/).
 
A couple of profiles:
* Politico profiles [Joe White, the UK’s ambassador to Silicon Valley](https://www.politico.com/news/2023/06/13/uk-silicon-valley-tech-00101543)

* From the New Statesman: [‘“World leaders now understand that cyber is a big issue”: Lindy Cameron on her first year as NCSC CEO’](https://www.newstatesman.com/spotlight/cybersecurity/2021/12/world-leaders-now-understand-that-cyber-security-is-a-really-big-issue-lindy-cameron-on-her-first-year-as-ncscs-ceo)
 
And finally…
* The Bennett Institute (Cambridge) explored [‘What The Beatles can teach us about AI’](https://www.bennettinstitute.cam.ac.uk/blog/ai-2/). It seems Macca himself saw some confused coverage of [the original story](https://twitter.com/BBCr4today/status/1668524309805973505), and decided he couldn’t [let it be](https://www.theguardian.com/music/2023/jun/23/paul-mccartney-says-theres-nothing-artificial-in-new-beatles-song-made-using-ai).