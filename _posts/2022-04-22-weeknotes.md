---
layout: post
author: Jeni Tennison
category: weeknotes
---
I am back from leave, and it's been a short week, in part because of the bank holiday on Monday, working with [Public Digital](https://public.digital/) on the [Bloomberg Philanthropies City Data Alliance](https://www.bloomberg.org/press/new-bloomberg-philanthropies-city-data-alliance-launches-in-the-u-s-latin-america-and-canada-with-60-million-investment/) on Tuesday, and attending the [Bennett Institute for Public Policy Annual Conference](https://www.bennettinstitute.cam.ac.uk/events/conference-2022/) on Friday.

<!--more-->

The highlight was running a workshop with [Research ICT Africa](https://researchictafrica.net/) to get to know each other better and start to explore possible research questions and topics for our work together, even while those people in the room based in South Africa struggled with last-minute changes to their [load shedding](https://theculturetrip.com/africa/south-africa/articles/load-shedding-what-it-is-and-why-is-it-affecting-south-africa/) schedules.

The conversation included concerns that are familiar motifs in conversations about data justice, ethics, and community participation, in particular around underlying data literacy, capacity and understanding to enable informed public participation in data governance. But it also highlighted some of the positives and negatives of the African context specifically: cultural traditions of communal decision making (nicely described in [this piece by Talitha Hlaka](https://merltech.org/data-governance-in-the-african-context/)) and societies that may be undemocratic, or where fundamental rights cannot be assumed to be in place. We'll be having another workshop in a few weeks to dig into these potential topics in more detail.

While I'm on the topic of interesting papers, it was great to see a piece in Vox this week on [Why it's so damn hard to make AI fair and unbiased](https://www.vox.com/future-perfect/22916602/ai-bias-fairness-tradeoffs-artificial-intelligence) which drew attention to the reality that making "unbiased" AI (or data) is non-sensical: all we can really do is choose the kind of bias it has. And that those choices should be made through participatory decision making, rather than being left up to the developers or procurers of these algorithmic systems. It's great to see this narrative reaching mainstream(ish) media, and there's a lot for us to learn from, at Connected by Data, in terms of how the story describes the problem by drawing it back to individual experience.

Two additional pieces of news this week, one bad and one good.

The bad news is that I found out that my application into the [FTX Foundation Future Fund](https://ftxfuturefund.org/) was unsuccessful. It's honestly not that surprising, given the speed with which I pulled the application together and the low maturity of this initiative, and at least they turned around a negative response within a couple of weeks, rather than wasting time with protracted back and forths, which means there was minimal wasted effort on our side. This is the first in what will undoubtedly be a long line of unsuccessful bids...

The good news is that I can now announce my first hire into Connected by Data. I'm over the moon that [Tim Davies](https://www.timdavies.org.uk/) will be joining at the beginning of May as Research Director. He will focus on designing and conducting research, particularly to support consumer-facing stories; keeping up to date on the latest research and thinking on open, collective and participative data governance; and building a strong community with other researchers who are active in the field. I'm extremely excited to be working with him.
