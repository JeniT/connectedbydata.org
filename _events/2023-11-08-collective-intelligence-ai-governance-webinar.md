---
layout: event
title: "Collective intelligence and AI governance"
image: 
upcoming: false
writeup: true
date: 2023-11-08
author: Maria Luciano
category: attending
project: 
---

The Democracy Network has organized a series of AI & Democracy webinars, and I attended the “[Using Collective Intelligence to Govern AI](https://www.youtube.com/watch?v=735W-w6rey0)” one. Flynn Devine, an Open AI grantee, presented his [Recursive Public](https://www.recursivepublic.com/) project, which uses a consensus-finding digital democratic process pioneered by [vTaiwan](https://www.bbc.com/news/technology-50127713) to set the agenda by mapping the big questions everyone thinks we need answers to.

<!--more-->

Interestingly, Flynn started his presentation by tackling my concerns after the Data & Society webinar: “we need participatory practices in AI that can move at the same pace as technology and societal norms, and adapt to make sure outputs maintain relevance and power.” So, what would it look like to surface and reintroduce interconnected deliberation processes once a process has been completed?

He went on to explain his use of “recursion” in four points:
* **Dynamic issues surfacing:** continually prioritise and address these issues as they arise, rather than being tied to a stagnant agenda.
* **Process chains for mass participation:** a series of interconnected deliberations to facilitate mass participation and assurance that the collective output remains representative and updated.
* **Time-fluid conversations:** continually feeding back outcomes into new deliberations, the recursive public ensures that the collective intelligence remains current.
* **Multiple audiences and outputs:** engage the many key stakeholders and continually refine these outputs, ensuring they resonate with the intended recipients.

The results of this project are yet to be shared, and my curiosity about the possible points of consensus continues to grow. One thing I’ll look forward to observing relates to one of the findings from a [Collective Intelligence Project](https://www.collective-intelligence.co.uk/) with Open AI around democratizing risk assessments, also presented by Flynn. When investigating “what does the U.S. public want to mitigate and measure when it comes to LLM risks and harms?”, [they noticed](https://static1.squarespace.com/static/631d02b2dfa9482a32db47ec/t/6556228ccd929249f767a65c/1700143757657/Participatory+AI+Risk+Prioritization+%7C+CIP.pdf) that people mostly care about creating good governance infrastructures into these processes rather than analyzing any specific risks. It seems to relate to the lack of trust in the governance systems being adopted by private companies, which tends to steer the conversation away from concrete risks and harms.